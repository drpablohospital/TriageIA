El juicio clínico, el triage y el lugar de la inteligencia artificial en medicina
La clasificación del triage constituye un modelo clínico basado esencialmente en inferencias bajo incertidumbre. Su propósito es anticipar el grado de urgencia de un paciente utilizando información fragmentaria: signos vitales en un momento específico, una descripción breve del motivo de consulta y la experiencia del personal de salud. Esta evaluación rápida está sujeta a múltiples fuentes de sesgo, como la carga laboral, la ansiedad del paciente o presentaciones clínicas atípicas. Además, la atención en urgencias es dinámica: una prioridad aparentemente baja puede tornarse crítica en cuestión de minutos. Por tanto, el triage no debe entenderse como un dictamen objetivo, sino como una estimación probabilística informada por patrones históricos y experiencia acumulada.

Esta lógica inferencial encuentra un paralelo en los modelos de inteligencia artificial (IA), que operan mediante el ajuste de funciones matemáticas a grandes volúmenes de datos estructurados. Algoritmos como las redes neuronales, los árboles de decisión o los modelos bayesianos aprenden a identificar correlaciones de alta dimensionalidad mediante la optimización de funciones de costo que maximizan la precisión predictiva en tareas clínicas específicas. En campos como la imagenología médica, algunos modelos, como CheXNet, han mostrado desempeños superiores a radiólogos humanos en la detección de patologías como neumonía o microcalcificaciones mamarias{1}. No obstante, estos sistemas no "comprenden" en un sentido humano; procesan patrones estadísticos, no significados.

El juicio clínico humano, por su parte, integra múltiples capas de procesamiento neurocognitivo. La toma de decisiones médicas ocurre no solo en función de datos explícitos, sino también de señales contextuales, conocimiento tácito y razonamiento intuitivo. Áreas como la corteza prefrontal dorsolateral, la ínsula anterior y la red de saliencia están implicadas en la gestión de incertidumbre clínica y la generación de intuiciones diagnósticas{2}. Investigadores como Damasio y Croskerry han descrito este fenómeno como el resultado de una interacción entre sistemas racionales y afectivos, lo que da lugar al llamado "ojo clínico"{3,4}. Desde otra perspectiva, Stephen Wolfram ha propuesto que la cognición humana puede entenderse como una forma de computación emergente que transforma información de manera no lineal, estructurando patrones a partir del caos aparente del entorno{5}. En este sentido, la intuición médica representa quizás el sistema de inferencia más complejo que existe, desarrollado a lo largo de millones de años de evolución biológica y siglos de práctica colectiva.

La inteligencia artificial médica, entonces, debe concebirse no como sustituto de este juicio, sino como su herramienta complementaria. Su potencial reside en detectar sesgos, mejorar la consistencia diagnóstica y servir como apoyo en decisiones clínicas críticas. En particular, puede resultar útil en procesos como el triage, donde la rapidez y precisión son fundamentales, pero donde también abundan las ambigüedades. La IA puede ayudar a estandarizar criterios, alertar sobre deterioros inminentes o revisar retrospectivamente las decisiones tomadas. Pero para ello debe situarse en una relación de cooperación con el conocimiento clínico, reconociendo que toda predicción algorítmica requiere contextualización humana. Como ha señalado Ludwik Fleck, los hechos científicos no existen independientemente del pensamiento colectivo que los produce{6}; los algoritmos clínicos, en consecuencia, no descubren verdades puras, sino que consolidan formas dominantes de observar, registrar y clasificar la realidad médica.

Esta reflexión es particularmente relevante en países como México, donde el acceso a tecnología médica suele estar limitado por barreras económicas o estructurales. Afortunadamente, muchas de estas herramientas de IA pueden democratizarse: existen modelos que pueden ejecutarse en computadoras locales, teléfonos inteligentes o navegadores web, sin necesidad de infraestructura hospitalaria compleja. Con una penetración de internet de 83.3 % y un 97 % de usuarios conectados mediante dispositivos móviles{7}, estas tecnologías tienen el potencial de llegar a una gran parte del personal médico en formación y servicio, incluso en regiones semiurbanas o rurales. Además, su carácter de código abierto y bajo costo las convierte en instrumentos adaptables a bases de datos locales, entrenadas con realidades clínicas particulares y no únicamente con datasets internacionales.

A pesar de este potencial, el desarrollo y uso de IA clínica conlleva una serie de responsabilidades epistemológicas y éticas. Como advirtió Leopoldo Zea, “toda verdad ha de probarse en la vida; si no, es inútil y peligrosa”{8}. La validez de un sistema automatizado no puede reducirse a su rendimiento estadístico en pruebas controladas; debe evaluarse por su capacidad de intervenir con justicia y pertinencia en contextos reales, donde las decisiones médicas tienen consecuencias vitales. El riesgo, si se omite este enfoque, es construir artefactos tecnológicamente sofisticados pero clínicamente irrelevantes o incluso dañinos.

Este imperativo ético cobra especial urgencia en ámbitos como el triage, donde las decisiones deben tomarse en segundos y con información incompleta. Aquí, el dato clínico no es neutro: representa el rastro formalizado de una vida humana que irrumpe en el sistema de salud con urgencia. Como sostuvo Emmanuel Lévinas, “el rostro del otro me ordena”{9}; es decir, el fundamento de toda ética médica es la responsabilidad ante la presencia concreta del otro. En esta línea, toda herramienta diagnóstica—humana o algorítmica—debe responder a esa interpelación. Un algoritmo que no reconozca esta dimensión corre el riesgo de volverse insensible o alienante.

Por tanto, el diseño de sistemas de IA en medicina debe cumplir tres principios esenciales: primero, reflejar fielmente la diversidad clínica y social de las poblaciones atendidas; segundo, retroalimentarse de manera continua a partir de la práctica médica real; y tercero, funcionar como herramienta de evaluación y mejora del desempeño clínico, sin aspirar a reemplazarlo. Solo bajo estas condiciones, la IA puede contribuir a una medicina más segura, justa y humana.

En última instancia, la inteligencia artificial no es una entidad ajena al pensamiento médico, sino una proyección estadística de nuestras propias estructuras cognitivas e inferenciales. Al igual que un modelo matemático condensa múltiples dimensiones en una función funcional, los algoritmos clínicos encapsulan nuestras aspiraciones, nuestras limitaciones y nuestras hipótesis sobre lo real. Cada sistema de IA es, en este sentido, una función aproximada de una distribución que no podemos conocer por completo, pero que seguimos intentando estimar. Conocer, en medicina, es también responder. Y toda forma de conocimiento clínico—algorítmico o humano—implica una forma de responsabilidad.

Referencias:

Rajpurkar P, Irvin J, Zhu K, et al. CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning. arXiv preprint arXiv:1711.05225. 2017.

Seeley WW, Menon V, Schatzberg AF, et al. Dissociable intrinsic connectivity networks for salience processing and executive control. J Neurosci. 2007;27(9):2349–2356.

Damasio AR. Descartes’ Error: Emotion, Reason, and the Human Brain. New York: Putnam; 1994.

Croskerry P. A universal model of diagnostic reasoning. Acad Med. 2009;84(8):1022–1028.

Wolfram S. A New Kind of Science. Champaign, IL: Wolfram Media; 2002.

Fleck L. Génesis y desarrollo de un hecho científico. Madrid: Alianza Editorial; 1986 [1935].

Instituto Federal de Telecomunicaciones. Estudio de hábitos de los usuarios de internet en México 2024. [Citado: 2025-07-08]. Disponible en: https://www.ift.org.mx

Zea L. El pensamiento latinoamericano. México: Fondo de Cultura Económica; 1981.

Lévinas E. Totalidad e infinito. Salamanca: Sígueme; 2000 [1961].
